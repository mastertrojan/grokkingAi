{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.38905609893065"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def ele_mul(multiplier, vector):\n",
    "    return [a * multiplier for a in vector]\n",
    "\n",
    "\n",
    "def ele_add(vec_a, vec_b):\n",
    "    return [a+b for a, b in zip(vec_a, vec_b)]\n",
    "\n",
    "\n",
    "def vector_sum(vec_a):\n",
    "    return sum(vec_a)\n",
    "\n",
    "\n",
    "def vector_average(vec_a):\n",
    "    return statistics.mean(vec_a)\n",
    "\n",
    "weights = np.array([0.1, 0.2, 0])\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = input.dot(weights)\n",
    "    return pred\n",
    "\n",
    "np.exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 3. ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concepts: Vector, Matrix, DOT Product (Weighted Sum)\n",
    "# Vector: List of numbers\n",
    "weights = np.array([.5,.5,.5])\n",
    "# Matrix: List of Vectors \n",
    "input = np.array([[1,1,1], [2,2,2]])\n",
    "# DOT Product: Multiplying input by weights and suming each row Vector * Weights \n",
    "# These are our predictions\n",
    "input.dot(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepts: \n",
    "Error: (prediction - goal_prediction) ^ 2\n",
    "\n",
    "When summing up error you don't want a - 10 and + 10 to cancel out also it penalizes larger error more compared to smaller errors\n",
    "\n",
    "Delta: pred - goal_pred\n",
    "\n",
    "how much a prediction should move up or down.\n",
    "\n",
    "weight_delta = input * delta //Scaled by the input\n",
    "\n",
    "alpha is used to scale the weight adjustment.\n",
    "\n",
    "forward propagation: Input is multiplied by weights to make a prediction.\n",
    "\n",
    "Backwardpropagation: Long distance error attribution. Delta's are propagated backward in the network to adjust weights depending on accuracy or error. Layer value is multplied by the last layers weight. It is like doing prediction backwards. For each weight multiply its input value by its output delta and increase weight by that much.\n",
    "\n",
    "Hidden Layer: Creates correlation and tends to be non-linear. It is used to remove noise or negative correlation using something like relu. Otherwise each layer would behave the exact same way as the previous layer.\n",
    "\n",
    "relu: The relu function is used to set negative correlation to 0 in order to not affect the weights going forward reducing the amount of noise being learned.\n",
    "\n",
    "**Hot Cold Learning**\n",
    "Is measuring the error and adjusting the weights by an arbitrary amount up or down. Make two predicition one with a higher weight and one with a lower weight, and than change the weight by that amount. Simple but very time consuming.The most popular way currently to adjust the error is by using Gradient Descent with uses the derivative to adjust the weight. \n",
    "\n",
    "**Gradient Descent:** \n",
    "Is a mathmatical function to find the minimum of a function in other words the 0 slope of a curve. It uses the derivitave to calculate the direction and amount of change for the next iteration. The derivative is the slope of the tangent line. The tangent line is the slope for a single point on the curve instead what most are used to which is between two points. We want to know at this specific point on the curve what is slope.\n",
    "\n",
    "Putting the concepts together we get:\n",
    "error = (prediction - goal_prediction) ^2\n",
    "delta = prediction - goal_prediction\n",
    "weights -= input * delta\n",
    "\n",
    "Dot product: In neural networks we consider the entire error of the prediction. \n",
    "\n",
    "\n",
    "normalization:\n",
    "\n",
    "Stochastic Gradient Descent:\n",
    "\n",
    "Idea of Signal: Signal is moved throught he network.\n",
    "\n",
    "Dropout:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.496   0.4955 -0.3445]\n"
     ]
    }
   ],
   "source": [
    "# Predicting on predictions neural networks are all about stacking\n",
    "wgt_1 = np.array([\n",
    "    [.1,.2,-.1],\n",
    "    [-.1, .1, .0],\n",
    "    [.1, .4,.1]])\n",
    "wgt_2 = np.array([[.3,1.1,-.3],\n",
    "                 [.1,.2,.0],\n",
    "                 [.0,1.3,.1]])\n",
    "\n",
    "weights = [wgt_1, wgt_2]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    hid = input.dot(weights[0])\n",
    "    pred = hid.dot(weights[1])\n",
    "    return pred\n",
    "\n",
    "toes = np.array([8.5, 9.5, 9.9, 9.0])\n",
    "wlrec = np.array([.65, .8, .8, .9])\n",
    "nfans = np.array([1.2, 1.3, .5, 1.0])\n",
    "\n",
    "input = np.array([toes[0], wlrec[0], nfans[0]])\n",
    "pred = neural_network(input, weights)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30250000000000005\n"
     ]
    }
   ],
   "source": [
    "# Measuring error (math nugget: multiply anything by itself to get a positive number,\n",
    "# Squaring amplifies big deviations, smaller numbers are not penalized as much.\n",
    "# Numbers < 1 get smaller while numbers > 1 get larger\n",
    "# Why only positive errors? When working with a larger data set you don't want to cancel out\n",
    "# the error ex. error of 1000 and -1000 when summing the total error of the NN you end up with 0! Perfect score\n",
    "# Error = (prediction - goal_pred)^2 -> mean squared error\n",
    "knob_weight = 0.5\n",
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "pred = input * knob_weight\n",
    "error = (pred - goal_pred) ** 2\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning in its simplest form is reducing the error to 0 \n",
    "#HOT COLD method\n",
    "error = ((input * weight) - goal_pred) **2\n",
    "up_weight = error * input\n",
    "last_error = 10\n",
    "delta = pred - goal_pred\n",
    "weight_delta = delta * input\n",
    "weight = weight - weight_delta\n",
    "if error < last_error:\n",
    "    last_error = error\n",
    "    weight += step_amount\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha used to normalize weights in case the input is very large\n",
    "#To avoid divergence, where a large input causes the error to get bigger\n",
    "#further away from the optimum 0 error\n",
    "# ![title](\"img/picture.png\")\n",
    "# from IPython.display import Image\n",
    "# Image(\"img/picture.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = ((input * weight) - goal_pred) **2\n",
    "up_weight = error * input\n",
    "last_error = 10\n",
    "delta = pred - goal_pred\n",
    "weight_delta = delta * input\n",
    "weight = weight - weight_delta\n",
    "if error < last_error:\n",
    "    last_error = error\n",
    "    weight += step_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:-0.19999999999999996\n",
      "Prediction:-0.2197117696238482\n",
      "Prediction:-0.6994235392476964\n",
      "Prediction:0.2814411518807589\n",
      "Prediction:-0.21827061774308942\n",
      "Prediction:-0.19798238736693752\n",
      "Error:4.056597230186805\n",
      "\n",
      "Prediction:-0.19740592661463396\n",
      "Prediction:-0.21711769623848237\n",
      "Prediction:-0.6976941569907857\n",
      "Prediction:0.28489991639458\n",
      "Prediction:-0.2156765443577236\n",
      "Prediction:-0.19538831398157153\n",
      "Error:4.0345359063731125\n",
      "\n",
      "Prediction:-0.19481185322926797\n",
      "Prediction:-0.21452362285311655\n",
      "Prediction:-0.6959647747338751\n",
      "Prediction:0.2883586809084011\n",
      "Prediction:-0.21308247097235777\n",
      "Prediction:-0.19279424059620553\n",
      "Error:4.012558323923154\n",
      "\n",
      "Prediction:-0.19221777984390198\n",
      "Prediction:-0.21192954946775072\n",
      "Prediction:-0.6942353924769644\n",
      "Prediction:0.2918174454222223\n",
      "Prediction:-0.21048839758699195\n",
      "Prediction:-0.19020016721083954\n",
      "Error:3.9906644828369306\n",
      "\n",
      "Prediction:-0.189623706458536\n",
      "Prediction:-0.2093354760823849\n",
      "Prediction:-0.6925060102200538\n",
      "Prediction:0.29527620993604353\n",
      "Prediction:-0.20789432420162612\n",
      "Prediction:-0.18760609382547355\n",
      "Error:3.9688543831144414\n",
      "\n",
      "Prediction:-0.18702963307317\n",
      "Prediction:-0.20674140269701907\n",
      "Prediction:-0.6907766279631431\n",
      "Prediction:0.29873497444986463\n",
      "Prediction:-0.2053002508162603\n",
      "Prediction:-0.18501202044010756\n",
      "Error:3.9471280247556866\n",
      "\n",
      "Prediction:-0.184435559687804\n",
      "Prediction:-0.20414732931165325\n",
      "Prediction:-0.6890472457062324\n",
      "Prediction:0.30219373896368573\n",
      "Prediction:-0.20270617743089447\n",
      "Prediction:-0.18241794705474157\n",
      "Error:3.925485407760667\n",
      "\n",
      "Prediction:-0.18184148630243802\n",
      "Prediction:-0.20155325592628742\n",
      "Prediction:-0.6873178634493218\n",
      "Prediction:0.30565250347750694\n",
      "Prediction:-0.20011210404552865\n",
      "Prediction:-0.17982387366937558\n",
      "Error:3.9039265321293812\n",
      "\n",
      "Prediction:-0.17924741291707202\n",
      "Prediction:-0.1989591825409216\n",
      "Prediction:-0.6855884811924111\n",
      "Prediction:0.30911126799132815\n",
      "Prediction:-0.19751803066016282\n",
      "Prediction:-0.1772298002840096\n",
      "Error:3.8824513978618307\n",
      "\n",
      "Prediction:-0.17665333953170603\n",
      "Prediction:-0.19636510915555577\n",
      "Prediction:-0.6838590989355005\n",
      "Prediction:0.31257003250514925\n",
      "Prediction:-0.194923957274797\n",
      "Prediction:-0.1746357268986436\n",
      "Error:3.8610600049580137\n",
      "\n",
      "Prediction:-0.17405926614634004\n",
      "Prediction:-0.19377103577018995\n",
      "Prediction:-0.6821297166785898\n",
      "Prediction:0.31602879701897035\n",
      "Prediction:-0.19232988388943117\n",
      "Prediction:-0.1720416535132776\n",
      "Error:3.839752353417931\n",
      "\n",
      "Prediction:-0.17146519276097405\n",
      "Prediction:-0.19117696238482412\n",
      "Prediction:-0.6804003344216791\n",
      "Prediction:0.31948756153279156\n",
      "Prediction:-0.18973581050406535\n",
      "Prediction:-0.1694475801279116\n",
      "Error:3.8185284432415836\n",
      "\n",
      "Prediction:-0.16887111937560806\n",
      "Prediction:-0.1885828889994583\n",
      "Prediction:-0.6786709521647685\n",
      "Prediction:0.3229463260466128\n",
      "Prediction:-0.18714173711869952\n",
      "Prediction:-0.16685350674254562\n",
      "Error:3.7973882744289704\n",
      "\n",
      "Prediction:-0.16627704599024207\n",
      "Prediction:-0.18598881561409247\n",
      "Prediction:-0.6769415699078578\n",
      "Prediction:0.3264050905604339\n",
      "Prediction:-0.1845476637333337\n",
      "Prediction:-0.16425943335717963\n",
      "Error:3.776331846980092\n",
      "\n",
      "Prediction:-0.16368297260487608\n",
      "Prediction:-0.18339474222872665\n",
      "Prediction:-0.6752121876509471\n",
      "Prediction:0.329863855074255\n",
      "Prediction:-0.18195359034796788\n",
      "Prediction:-0.16166535997181364\n",
      "Error:3.755359160894949\n",
      "\n",
      "Prediction:-0.16108889921951008\n",
      "Prediction:-0.18080066884336082\n",
      "Prediction:-0.6734828053940365\n",
      "Prediction:0.3333226195880761\n",
      "Prediction:-0.17935951696260205\n",
      "Prediction:-0.15907128658644765\n",
      "Error:3.7344702161735386\n",
      "\n",
      "Prediction:-0.1584948258341441\n",
      "Prediction:-0.178206595457995\n",
      "Prediction:-0.6717534231371258\n",
      "Prediction:0.3367813841018974\n",
      "Prediction:-0.17676544357723623\n",
      "Prediction:-0.15647721320108166\n",
      "Error:3.713665012815863\n",
      "\n",
      "Prediction:-0.1559007524487781\n",
      "Prediction:-0.17561252207262917\n",
      "Prediction:-0.6700240408802152\n",
      "Prediction:0.3402401486157185\n",
      "Prediction:-0.1741713701918704\n",
      "Prediction:-0.15388313981571566\n",
      "Error:3.692943550821922\n",
      "\n",
      "Prediction:-0.1533066790634121\n",
      "Prediction:-0.17301844868726335\n",
      "Prediction:-0.6682946586233045\n",
      "Prediction:0.3436989131295396\n",
      "Prediction:-0.17157729680650458\n",
      "Prediction:-0.15128906643034967\n",
      "Error:3.6723058301917155\n",
      "\n",
      "Prediction:-0.15071260567804612\n",
      "Prediction:-0.17042437530189752\n",
      "Prediction:-0.6665652763663938\n",
      "Prediction:0.3471576776433609\n",
      "Prediction:-0.16898322342113875\n",
      "Prediction:-0.14869499304498368\n",
      "Error:3.6517518509252445\n",
      "\n",
      "Prediction:-0.14811853229268013\n",
      "Prediction:-0.1678303019165317\n",
      "Prediction:-0.6648358941094832\n",
      "Prediction:0.350616442157182\n",
      "Prediction:-0.16638915003577293\n",
      "Prediction:-0.1461009196596177\n",
      "Error:3.631281613022507\n",
      "\n",
      "Prediction:-0.14552445890731414\n",
      "Prediction:-0.16523622853116587\n",
      "Prediction:-0.6631065118525725\n",
      "Prediction:0.3540752066710031\n",
      "Prediction:-0.1637950766504071\n",
      "Prediction:-0.1435068462742517\n",
      "Error:3.6108951164835035\n",
      "\n",
      "Prediction:-0.14293038552194814\n",
      "Prediction:-0.16264215514580005\n",
      "Prediction:-0.6613771295956619\n",
      "Prediction:0.3575339711848242\n",
      "Prediction:-0.16120100326504128\n",
      "Prediction:-0.1409127728888857\n",
      "Error:3.590592361308236\n",
      "\n",
      "Prediction:-0.14033631213658215\n",
      "Prediction:-0.16004808176043422\n",
      "Prediction:-0.6596477473387512\n",
      "Prediction:0.3609927356986453\n",
      "Prediction:-0.1586069298796754\n",
      "Prediction:-0.13831869950351972\n",
      "Error:3.570373347496701\n",
      "\n",
      "Prediction:-0.13774223875121616\n",
      "Prediction:-0.1574540083750683\n",
      "Prediction:-0.6579183650818405\n",
      "Prediction:0.36445150021246664\n",
      "Prediction:-0.1560128564943094\n",
      "Prediction:-0.13572462611815372\n",
      "Error:3.550238075048901\n",
      "\n",
      "Prediction:-0.13514816536585017\n",
      "Prediction:-0.1548599349897023\n",
      "Prediction:-0.6561889828249299\n",
      "Prediction:0.36791026472628796\n",
      "Prediction:-0.1534187831089434\n",
      "Prediction:-0.13313055273278773\n",
      "Error:3.530186543964835\n",
      "\n",
      "Prediction:-0.13255409198048418\n",
      "Prediction:-0.1522658616043363\n",
      "Prediction:-0.6544596005680192\n",
      "Prediction:0.3713690292401093\n",
      "Prediction:-0.15082470972357742\n",
      "Prediction:-0.13053647934742174\n",
      "Error:3.5102187542445034\n",
      "\n",
      "Prediction:-0.1299600185951182\n",
      "Prediction:-0.14967178821897031\n",
      "Prediction:-0.6527302183111086\n",
      "Prediction:0.3748277937539306\n",
      "Prediction:-0.14823063633821143\n",
      "Prediction:-0.12794240596205575\n",
      "Error:3.4903347058879066\n",
      "\n",
      "Prediction:-0.1273659452097522\n",
      "Prediction:-0.14707771483360432\n",
      "Prediction:-0.6510008360541979\n",
      "Prediction:0.3782865582677519\n",
      "Prediction:-0.14563656295284544\n",
      "Prediction:-0.12534833257668976\n",
      "Error:3.4705343988950443\n",
      "\n",
      "Prediction:-0.1247718718243862\n",
      "Prediction:-0.14448364144823833\n",
      "Prediction:-0.6492714537972872\n",
      "Prediction:0.38174532278157325\n",
      "Prediction:-0.14304248956747945\n",
      "Prediction:-0.12275425919132377\n",
      "Error:3.450817833265916\n",
      "\n",
      "Prediction:-0.12217779843902021\n",
      "Prediction:-0.14188956806287234\n",
      "Prediction:-0.6475420715403766\n",
      "Prediction:0.38520408729539457\n",
      "Prediction:-0.14044841618211346\n",
      "Prediction:-0.12016018580595778\n",
      "Error:3.4311850090005227\n",
      "\n",
      "Prediction:-0.11958372505365422\n",
      "Prediction:-0.13929549467750635\n",
      "Prediction:-0.6458126892834659\n",
      "Prediction:0.3886628518092159\n",
      "Prediction:-0.13785434279674746\n",
      "Prediction:-0.11756611242059178\n",
      "Error:3.4116359260988642\n",
      "\n",
      "Prediction:-0.11698965166828823\n",
      "Prediction:-0.13670142129214036\n",
      "Prediction:-0.6440833070265553\n",
      "Prediction:0.3921216163230372\n",
      "Prediction:-0.13526026941138147\n",
      "Prediction:-0.11497203903522579\n",
      "Error:3.3921705845609393\n",
      "\n",
      "Prediction:-0.11439557828292224\n",
      "Prediction:-0.13410734790677437\n",
      "Prediction:-0.6423539247696446\n",
      "Prediction:0.39558038083685854\n",
      "Prediction:-0.13266619602601548\n",
      "Prediction:-0.1123779656498598\n",
      "Error:3.37278898438675\n",
      "\n",
      "Prediction:-0.11180150489755625\n",
      "Prediction:-0.13151327452140837\n",
      "Prediction:-0.6406245425127339\n",
      "Prediction:0.39903914535067986\n",
      "Prediction:-0.1300721226406495\n",
      "Prediction:-0.10978389226449381\n",
      "Error:3.3534911255762943\n",
      "\n",
      "Prediction:-0.10920743151219026\n",
      "Prediction:-0.12891920113604238\n",
      "Prediction:-0.6388951602558233\n",
      "Prediction:0.4024979098645012\n",
      "Prediction:-0.1274780492552835\n",
      "Prediction:-0.10718981887912782\n",
      "Error:3.3342770081295727\n",
      "\n",
      "Prediction:-0.10661335812682426\n",
      "Prediction:-0.1263251277506764\n",
      "Prediction:-0.6371657779989126\n",
      "Prediction:0.4059566743783225\n",
      "Prediction:-0.12488397586991751\n",
      "Prediction:-0.10459574549376183\n",
      "Error:3.3151466320465866\n",
      "\n",
      "Prediction:-0.10401928474145827\n",
      "Prediction:-0.1237310543653104\n",
      "Prediction:-0.635436395742002\n",
      "Prediction:0.4094154388921438\n",
      "Prediction:-0.12228990248455152\n",
      "Prediction:-0.10200167210839584\n",
      "Error:3.2960999973273344\n",
      "\n",
      "Prediction:-0.10142521135609228\n",
      "Prediction:-0.12113698097994441\n",
      "Prediction:-0.6337070134850913\n",
      "Prediction:0.41287420340596515\n",
      "Prediction:-0.11969582909918552\n",
      "Prediction:-0.09940759872302984\n",
      "Error:3.2771371039718167\n",
      "\n",
      "Prediction:-0.09883113797072629\n",
      "Prediction:-0.11854290759457842\n",
      "Prediction:-0.6319776312281806\n",
      "Prediction:0.41633296791978647\n",
      "Prediction:-0.11710175571381953\n",
      "Prediction:-0.09681352533766385\n",
      "Error:3.258257951980034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "weights = np.array([0.5,0.48,-0.7]) \n",
    "alpha = 0.1\n",
    "streetlights = np.array( [ [ 1, 0, 1 ],\n",
    "                          [ 0, 1, 1 ],\n",
    "                          [ 0, 0, 1 ],\n",
    "                          [ 1, 1, 1 ],\n",
    "                          [ 0, 1, 1 ],\n",
    "                          [ 1, 0, 1 ], ] )\n",
    "walk_vs_stop = np.array( [ 0, 1, 0, 1, 1, 0 ] )\n",
    "\n",
    "for iteration in range(40):\n",
    "    error_for_all_lights = 0\n",
    "    for row_index in range(len(walk_vs_stop)):\n",
    "        input = streetlights[row_index]\n",
    "        goal_pred = walk_vs_stop[row_index]\n",
    "        pred = input.dot(weights)\n",
    "        \n",
    "        error = (goal_pred - pred) **2\n",
    "        error_for_all_lights += error\n",
    "        detla = goal_pred - pred\n",
    "        weights -= alpha * (delta * input)\n",
    "        print(\"Prediction:\" + str(pred)) \n",
    "    print(\"Error:\" + str(error_for_all_lights) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.19999999999999996"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.array([0.5,0.48,-0.7]) \n",
    "np.array([ 1, 0, 1 ]).dot(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 6)\n",
      "[[1 0 0 1 0 1]\n",
      " [0 1 0 1 1 0]\n",
      " [1 1 1 1 1 1]]\n",
      "(6, 3)\n",
      "[[1 0 1]\n",
      " [0 1 1]\n",
      " [0 0 1]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "#.T transposes the entire shape\n",
    "print(streetlights.T.shape)\n",
    "print(streetlights.T)\n",
    "print(streetlights.shape)\n",
    "print(streetlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streetlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streetlights[0:0 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binary Fun 1 and 0 evaluate to the same binary\n",
    "(1 > 0) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.9185144087908717\n",
      "Error:0.04093927114936257\n",
      "Error:0.004079693852295429\n",
      "Error:0.0003040583756873149\n",
      "Error:2.0415907027785762e-05\n",
      "Error:1.3315609362142274e-06\n"
     ]
    }
   ],
   "source": [
    "def relu(x):\n",
    "    return (x>0)*x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output>0\n",
    "\n",
    "streetlights = np.array( [ [ 1, 0, 1 ],\n",
    "                          [ 0, 1, 1 ],\n",
    "                          [ 0, 0, 1 ],\n",
    "                          [ 1, 1, 1 ],\n",
    "                          [ 0, 1, 1 ],\n",
    "                          [ 1, 0, 1 ], ] )\n",
    "\n",
    "walk_vs_stop = np.array( [[ 0, 1, 0, 1, 1, 0 ]] ).T\n",
    "\n",
    "#weights = np.array([0.5,0.48,-0.7]) \n",
    "alpha = 0.2\n",
    "hidden_size = 4\n",
    "\n",
    "weights_0_1 = 2*np.random.random((3,hidden_size)) - 1 \n",
    "weights_1_2 = 2*np.random.random((hidden_size,1)) - 1\n",
    "\n",
    "for iteration in range(60):\n",
    "    layer_2_error = 0\n",
    "    for i in range(len(streetlights)):\n",
    "        layer_0 = streetlights[i:i + 1] #gets nested list\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))      \n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
    "        layer_2_delta = (layer_2 - walk_vs_stop[i:i+1])      \n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\n",
    "        layer_1_delta *= relu2deriv(layer_1)\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)      \n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "    if(iteration % 10 == 9):\n",
    "        print(\"Error:\" + str(layer_2_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.58401515e-09]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(layer_2 - walk_vs_stop[i:i+1]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[ 1, 2, 4 ],[ 5, 6, 1 ],])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepts:\n",
    "Delta: how much a prediction should move up or down.\n",
    "\n",
    "forward propagation: Input is multiplied by weights to make a prediction. \n",
    "\n",
    "Backwardpropagation: Long distance error attribution. Delta's are propagated backward in the network to adjust weights depending on accuracy or error. Layer value is multplied by the last layers weight. \n",
    "It is like doing prediction backwards. For each weight multiply its input value by its output delta and increase weight by that much. \n",
    "\n",
    "Hidden Layer: Creates correlation and tends to be non-linear. It is used to remove noise or negative correlation using something like relu. Otherwise each layer would behave the exact same way as the previous layer. \n",
    "\n",
    "relu: The relu function is used to set negative correlation to 0 in order to not affect the weights going forward reducing the amount of noise being learned. \n",
    "\n",
    "normalization:\n",
    "\n",
    "Stochastic Gradient Descent:\n",
    "\n",
    "Idea of Signal: Signal is moved throught he network.\n",
    "\n",
    "Dropout: Used to avoid overfitting, with functions like relu, tanh, sigmoid and softmax\n",
    "\n",
    "**Activation functions** Used to create non linear networks sigmoid and tanh are used for hidden layers and softmax is used to the final/prediction layer since\n",
    "\n",
    "Softmax: softmax raises each input value exponentially and then  divides by the layer’s sum. It increases what is called the sharpness of attenuation. Meaning if it predicts higher for one output it will predict lower for the others, which is great for labeling think mnist it will predict 80% its a 2 and only 18% its a 3. \n",
    "\n",
    "Adding a activation function to a layer is pretty straight forward call it on the input and weights \n",
    "layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "back propagating we need to get the derivative. Good activation function have an non intensive way to compute the derivative or slope. \n",
    "ex.\n",
    "Relu has a linear slope. \n",
    "def relu(x):    \n",
    "    return (x >= 0) * x \n",
    "    \n",
    "def relu2deriv(output):    \n",
    "    return output >= 0 \n",
    "\n",
    "Multiplying delta by the slope To compute layer_delta, multiply the backpropagated delta by the layer’s slope.\n",
    "\n",
    "Sigmoid: 1/(1 + 2.718281^(opposite of input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\szaba\\Anaconda3\\envs\\aind\\lib\\site-packages\\ipykernel\\__main__.py:45: RuntimeWarning: overflow encountered in square\n",
      "C:\\Users\\szaba\\Anaconda3\\envs\\aind\\lib\\site-packages\\ipykernel\\__main__.py:19: RuntimeWarning: invalid value encountered in greater_equal\n",
      "C:\\Users\\szaba\\Anaconda3\\envs\\aind\\lib\\site-packages\\ipykernel\\__main__.py:19: RuntimeWarning: invalid value encountered in multiply\n",
      "C:\\Users\\szaba\\Anaconda3\\envs\\aind\\lib\\site-packages\\ipykernel\\__main__.py:21: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:299 Error:nan Correct:0.097"
     ]
    }
   ],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x:(x>=0) * x # returns x if x > 0, return 0 otherwise\n",
    "relu2deriv = lambda x: x>=0 # returns 1 for input > 0, return 0 otherwise\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image,hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        error += np.sum((labels[i:i+1] - layer_2) ** 2)\n",
    "        correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                        np.argmax(labels[i:i+1]))\n",
    "\n",
    "        layer_2_delta = (labels[i:i+1] - layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)\\\n",
    "                                    * relu2deriv(layer_1)\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    sys.stdout.write(\"\\r I:\"+str(j)+ \\\n",
    "                     \" Train-Err:\" + str(error/float(len(images)))[0:5] +\\\n",
    "                     \" Train-Acc:\" + str(correct_cnt/float(len(images))))\n",
    "    \n",
    "    if(j % 10 == 0 or j == iterations-1):\n",
    "        error, correct_cnt = (0.0, 0)\n",
    "\n",
    "        for i in range(len(test_images)):\n",
    "\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "            error += np.sum((test_labels[i:i+1] - layer_2) ** 2)\n",
    "            correct_cnt += int(np.argmax(layer_2) == \\\n",
    "                                            np.argmax(test_labels[i:i+1]))\n",
    "        sys.stdout.write(\" Test-Err:\" + str(error/float(len(test_images)))[0:5] +\\\n",
    "                         \" Test-Acc:\" + str(correct_cnt/float(len(test_images))))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist with activation functions:\n",
    "relu\n",
    "tanh\n",
    "sigma\n",
    "softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Acc:0.394 Train-Acc:0.156\n",
      "I:10 Test-Acc:0.6867 Train-Acc:0.723\n",
      "I:20 Test-Acc:0.7025 Train-Acc:0.732\n",
      "I:30 Test-Acc:0.734 Train-Acc:0.763\n",
      "I:40 Test-Acc:0.7663 Train-Acc:0.794\n",
      "I:50 Test-Acc:0.7913 Train-Acc:0.819\n",
      "I:60 Test-Acc:0.8102 Train-Acc:0.849\n",
      "I:70 Test-Acc:0.8228 Train-Acc:0.864\n",
      "I:80 Test-Acc:0.831 Train-Acc:0.867\n",
      "I:90 Test-Acc:0.8364 Train-Acc:0.885\n",
      "I:100 Test-Acc:0.8407 Train-Acc:0.883\n",
      "I:110 Test-Acc:0.845 Train-Acc:0.891\n",
      "I:120 Test-Acc:0.8481 Train-Acc:0.901\n",
      "I:130 Test-Acc:0.8505 Train-Acc:0.901\n",
      "I:140 Test-Acc:0.8526 Train-Acc:0.905\n",
      "I:150 Test-Acc:0.8555 Train-Acc:0.914\n",
      "I:160 Test-Acc:0.8577 Train-Acc:0.925\n",
      "I:170 Test-Acc:0.8596 Train-Acc:0.918\n",
      "I:180 Test-Acc:0.8619 Train-Acc:0.933\n",
      "I:190 Test-Acc:0.863 Train-Acc:0.933\n",
      "I:200 Test-Acc:0.8642 Train-Acc:0.926\n",
      "I:210 Test-Acc:0.8653 Train-Acc:0.931\n",
      "I:220 Test-Acc:0.8668 Train-Acc:0.93\n",
      "I:230 Test-Acc:0.8672 Train-Acc:0.937\n",
      "I:240 Test-Acc:0.8681 Train-Acc:0.938\n",
      "I:250 Test-Acc:0.8687 Train-Acc:0.937\n",
      "I:260 Test-Acc:0.8684 Train-Acc:0.945\n",
      "I:270 Test-Acc:0.8703 Train-Acc:0.951\n",
      "I:280 Test-Acc:0.8699 Train-Acc:0.949\n",
      "I:290 Test-Acc:0.8701 Train-Acc:0.94"
     ]
    }
   ],
   "source": [
    "import numpy as np, sys\n",
    "np.random.seed(1)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = (x_train[0:1000].reshape(1000,28*28) / 255, y_train[0:1000])\n",
    "\n",
    "one_hot_labels = np.zeros((len(labels),10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test),28*28) / 255\n",
    "test_labels = np.zeros((len(y_test),10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh2deriv(output):\n",
    "    return 1 - (output ** 2)\n",
    "\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)\n",
    "\n",
    "alpha, iterations, hidden_size = (2, 300, 100)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.02*np.random.random((pixels_per_image,hidden_size))-0.01\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,num_labels)) - 0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for i in range(int(len(images) / batch_size)):\n",
    "        batch_start, batch_end=((i * batch_size),((i+1)*batch_size))\n",
    "        layer_0 = images[batch_start:batch_end]\n",
    "        layer_1 = tanh(np.dot(layer_0,weights_0_1))\n",
    "        dropout_mask = np.random.randint(2,size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = softmax(np.dot(layer_1,weights_1_2))\n",
    "\n",
    "        for k in range(batch_size):\n",
    "            correct_cnt += int(np.argmax(layer_2[k:k+1]) == np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
    "\n",
    "        layer_2_delta = (labels[batch_start:batch_end]-layer_2) / (batch_size * layer_2.shape[0])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha * layer_0.T.dot(layer_1_delta)\n",
    "\n",
    "    test_correct_cnt = 0\n",
    "\n",
    "    for i in range(len(test_images)):\n",
    "\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = tanh(np.dot(layer_0,weights_0_1))\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "\n",
    "        test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[i:i+1]))\n",
    "    if(j % 10 == 0):\n",
    "        sys.stdout.write(\"\\n\"+ \\\n",
    "         \"I:\" + str(j) + \\\n",
    "         \" Test-Acc:\"+str(test_correct_cnt/float(len(test_images)))+\\\n",
    "         \" Train-Acc:\" + str(correct_cnt/float(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
