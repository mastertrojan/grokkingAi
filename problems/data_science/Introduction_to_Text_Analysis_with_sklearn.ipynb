{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to pandas and sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation System\n",
    "We live in a world surrounded by recommendation systems - our shopping habbits, our reading habits, political opinions are heavily influenced by recommendation algorithms. So lets take a closer look at how to build a basic recommendation system.\n",
    "\n",
    "Simply put a recommendation system learns from your previous behavior and tries to recommend items that are similar to your previous choices. While there are a multitude of approaches for building recommendation systems, we will take a simple approach that is easy to understand and has a reasonable performance.\n",
    "\n",
    "For this exercise we will build a recommendation system that predicts which talks you'll enjoy at a conference - specifically our favorite conference Pycon!\n",
    "\n",
    "### Before you proceed\n",
    "This project is still in alpha stage. Bugs, typos, spelling, grammar, terminologies - there's every scope of finding bugs. If you have found one - [open an issue on github](https://github.com/chicagopython/CodingWorkshops/issues/new). Pull Requests with corrections, fixes and enhancements will be received with open arms! Don't forget to add yourself to the [list of contributors to this project](https://github.com/chicagopython/CodingWorkshops/blob/master/README.md). \n",
    "\n",
    "\n",
    "#### Recommendation for Pycon talks\n",
    "Take a look at 2018 [schedule](https://us.pycon.org/2018/schedule/).\n",
    "With 32 tuotorials, 12 sponsor workshops, 16 talks at the education summit, and 95 talks at the main conference - Pycon has a lot to offer. Reading through all the talk descriptions and filtering out the ones that you should go to is a tedious process. \n",
    "Lets build a recommendation system that recommends talks from Pycon 2018, based on the ones that a person went to in 2017. This way the attendee does not waste any time deciding which talk to go to and spend more time making friends on the hallway track! \n",
    "\n",
    "We will be using [`pandas`](https://pandas.pydata.org/) and [`scikit-learn`](http://scikit-learn.org/) to build the recommnedation system using the text description of talks.\n",
    "\n",
    "\n",
    "\n",
    "### Definitions\n",
    "#### Documents\n",
    "In our example the talk descriptions make up the documents\n",
    "#### Class\n",
    "We have two classes to classify our documents\n",
    "- The talks that the attendee would like to see \"in person\". Denoted by 1\n",
    "- The talks that the attendee would watch \"later online\". Denoted by 0\n",
    "\n",
    "A talk description is labeled 0 would mean the user has chosen to watch it later and a label 1 would mean the user has chose to watch it in person.\n",
    "\n",
    "### Supervised Learning\n",
    "In Supervised learning we inspect each observation in a given dataset and manually label them. These manually labeled data is used to construct a model that can predict the labels on new data. We will use a Supervised Learning technique called Support Vector Machines.\n",
    "\n",
    "In unsupervised learning we do not need any manual labeling. The recommendation system finds the pattern in the data to build a model that can be used for recommendation.\n",
    "\n",
    "### Dataset\n",
    "The dataset contains the talk description and speaker details from Pycon 2017 and 2018. All the 2017 talk data has been labeled by a user who has been to Pycon 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages installation\n",
    "The following packages are needed for this project. Execute the cell below to install them. \n",
    "\n",
    "    numpy==1.14.2\n",
    "    pandas==0.22.0\n",
    "    python-dateutil==2.7.2\n",
    "    pytz==2018.4\n",
    "    scikit-learn==0.19.1\n",
    "    scipy==1.0.1\n",
    "    six==1.11.0\n",
    "    sklearn==0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask==0.12.2 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 1)) (0.12.2)\n",
      "Requirement already satisfied: Flask_RESTful==0.3.6 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.6)\n",
      "Requirement already satisfied: numpy==1.14.2 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 3)) (1.14.2)\n",
      "Requirement already satisfied: pandas==0.22.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 4)) (0.22.0)\n",
      "Requirement already satisfied: python-dateutil==2.7.2 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 5)) (2.7.2)\n",
      "Requirement already satisfied: pytz==2018.4 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 6)) (2018.4)\n",
      "Requirement already satisfied: scikit-learn==0.19.1 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 7)) (0.19.1)\n",
      "Requirement already satisfied: scipy==1.0.1 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: six==1.11.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 9)) (1.11.0)\n",
      "Requirement already satisfied: sklearn==0.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 10)) (0.0)\n",
      "Requirement already satisfied: jupyter in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from -r requirements.txt (line 11)) (1.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.4 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from Flask==0.12.2->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: click>=2.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from Flask==0.12.2->-r requirements.txt (line 1)) (7.0)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from Flask==0.12.2->-r requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: itsdangerous>=0.21 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from Flask==0.12.2->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: aniso8601>=0.82 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from Flask_RESTful==0.3.6->-r requirements.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: notebook in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter->-r requirements.txt (line 11)) (5.5.0)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter->-r requirements.txt (line 11)) (4.3.1)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter->-r requirements.txt (line 11)) (5.2.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter->-r requirements.txt (line 11)) (5.3.1)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter->-r requirements.txt (line 11)) (4.8.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter->-r requirements.txt (line 11)) (7.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from Jinja2>=2.4->Flask==0.12.2->-r requirements.txt (line 1)) (1.0)\n",
      "Requirement already satisfied: tornado>=4 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (5.0.2)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (4.3.2)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (5.2.3)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.8.1)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (17.0.0)\n",
      "Requirement already satisfied: nbformat in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (4.4.0)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 11)) (6.4.0)\n",
      "Requirement already satisfied: prompt_toolkit<2.0.0,>=1.0.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 11)) (1.0.15)\n",
      "Requirement already satisfied: pygments in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jupyter-console->jupyter->-r requirements.txt (line 11)) (2.2.0)\n",
      "Requirement already satisfied: mistune>=0.7.4 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.8.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.2.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (2.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: testpath in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.3.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.2.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipywidgets->jupyter->-r requirements.txt (line 11)) (3.2.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from traitlets>=4.2.1->notebook->jupyter->-r requirements.txt (line 11)) (4.3.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from nbformat->notebook->jupyter->-r requirements.txt (line 11)) (2.6.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (39.1.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.7.4)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.12.0)\n",
      "Requirement already satisfied: win-unicode-console>=0.5; sys_platform == \"win32\" and python_version < \"3.6\" in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.5)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.3.9)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from prompt_toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.1.7)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 11)) (1.0.1)\n",
      "Requirement already satisfied: parso>=0.2.0 in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from jedi>=0.10->ipython->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\szaba\\anaconda3\\envs\\aind\\lib\\site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->jupyter->-r requirements.txt (line 11)) (0.5.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkl-fft 1.0.0 requires cython, which is not installed.\n",
      "mkl-random 1.0.1 requires cython, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A: Load the data\n",
    "The data directory contains the snapshot of one such user's labeling - lets load that up and start with our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>presenters</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>location</th>\n",
       "      <th>talk_dt</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5 ways to deploy your Python web app in 2017</td>\n",
       "      <td>You’ve built a fine Python web application and...</td>\n",
       "      <td>Andrew T. Baker</td>\n",
       "      <td>2018-04-19 00:59:20.151875</td>\n",
       "      <td>2018-04-19 00:59:20.151875</td>\n",
       "      <td>Portland Ballroom 252–253</td>\n",
       "      <td>2017-05-08 15:15:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A gentle introduction to deep learning with Te...</td>\n",
       "      <td>Deep learning's explosion of spectacular resul...</td>\n",
       "      <td>Michelle Fullwood</td>\n",
       "      <td>2018-04-19 00:59:20.158338</td>\n",
       "      <td>2018-04-19 00:59:20.158338</td>\n",
       "      <td>Oregon Ballroom 203–204</td>\n",
       "      <td>2017-05-08 16:15:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aiosmtpd - A better asyncio based SMTP server</td>\n",
       "      <td>smtpd.py has been in the standard library for ...</td>\n",
       "      <td>Barry Warsaw</td>\n",
       "      <td>2018-04-19 00:59:20.161866</td>\n",
       "      <td>2018-04-19 00:59:20.161866</td>\n",
       "      <td>Oregon Ballroom 203–204</td>\n",
       "      <td>2017-05-08 14:30:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Algorithmic Music Generation</td>\n",
       "      <td>Music is mainly an artistic act of inspired cr...</td>\n",
       "      <td>Padmaja V Bhagwat</td>\n",
       "      <td>2018-04-19 00:59:20.165526</td>\n",
       "      <td>2018-04-19 00:59:20.165526</td>\n",
       "      <td>Portland Ballroom 251 &amp; 258</td>\n",
       "      <td>2017-05-08 17:10:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>An Introduction to Reinforcement Learning</td>\n",
       "      <td>Reinforcement learning (RL) is a subfield of m...</td>\n",
       "      <td>Jessica Forde</td>\n",
       "      <td>2018-04-19 00:59:20.169075</td>\n",
       "      <td>2018-04-19 00:59:20.169075</td>\n",
       "      <td>Portland Ballroom 252–253</td>\n",
       "      <td>2017-05-08 13:40:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1       5 ways to deploy your Python web app in 2017   \n",
       "1   2  A gentle introduction to deep learning with Te...   \n",
       "2   3      aiosmtpd - A better asyncio based SMTP server   \n",
       "3   4                       Algorithmic Music Generation   \n",
       "4   5          An Introduction to Reinforcement Learning   \n",
       "\n",
       "                                         description         presenters  \\\n",
       "0  You’ve built a fine Python web application and...    Andrew T. Baker   \n",
       "1  Deep learning's explosion of spectacular resul...  Michelle Fullwood   \n",
       "2  smtpd.py has been in the standard library for ...       Barry Warsaw   \n",
       "3  Music is mainly an artistic act of inspired cr...  Padmaja V Bhagwat   \n",
       "4  Reinforcement learning (RL) is a subfield of m...      Jessica Forde   \n",
       "\n",
       "                 date_created               date_modified  \\\n",
       "0  2018-04-19 00:59:20.151875  2018-04-19 00:59:20.151875   \n",
       "1  2018-04-19 00:59:20.158338  2018-04-19 00:59:20.158338   \n",
       "2  2018-04-19 00:59:20.161866  2018-04-19 00:59:20.161866   \n",
       "3  2018-04-19 00:59:20.165526  2018-04-19 00:59:20.165526   \n",
       "4  2018-04-19 00:59:20.169075  2018-04-19 00:59:20.169075   \n",
       "\n",
       "                      location                     talk_dt  year  label  \n",
       "0    Portland Ballroom 252–253  2017-05-08 15:15:00.000000  2017    0.0  \n",
       "1      Oregon Ballroom 203–204  2017-05-08 16:15:00.000000  2017    0.0  \n",
       "2      Oregon Ballroom 203–204  2017-05-08 14:30:00.000000  2017    1.0  \n",
       "3  Portland Ballroom 251 & 258  2017-05-08 17:10:00.000000  2017    0.0  \n",
       "4    Portland Ballroom 252–253  2017-05-08 13:40:00.000000  2017    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('talks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief description of the interesting fields.\n",
    "\n",
    "variable | description  \n",
    "------|------|\n",
    "`title`|Title of the talk\n",
    "`description`|Description of the talk\n",
    "`year`|Is it a `2017` talk or `2018`  \n",
    "`label`|`1` indicates the user preferred seeing the talk in person,<br> `0` indicates they would schedule it for later.\n",
    "\n",
    "Note all 2018 talks are set to 1. However they are only placeholders, and are not used in training the model. We will  use 2017 data for training, and predict the labels on the 2018 talks.\n",
    "\n",
    "Lets start by selecting the 2017 talk descriptions that were labeled by the user for watching in person.\n",
    "\n",
    "```python\n",
    "df[(df.year==2017) & (df.label==1)]['description']\n",
    "```\n",
    "\n",
    "Print the description of the talks that the user preferred watching in person. How many such talks are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Select 2017 talk description and labels from the Pandas dataframe. How many of them are present? Do the same for 2018 talks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     smtpd.py has been in the standard library for ...\n",
       "7     AWS is one of the best-known cloud vendors. Us...\n",
       "8     Decorators are a syntactically-pleasing way of...\n",
       "9     Designing a good command line tool is challeng...\n",
       "13    Do you have a stream of data that you would li...\n",
       "16    Are you running a Web application? Do you suff...\n",
       "18    Python 3.6 was released in December of 2016 an...\n",
       "19    Did you ever need to create an application who...\n",
       "20    One of the nicest things about Python communit...\n",
       "22       \"Four shalt thou not count, neither count t...\n",
       "24    A popular way of improving websites is to run ...\n",
       "25    Recently, networking vendors and Silicon Valle...\n",
       "34    We all know Python is a powerful and expressiv...\n",
       "35    Over the last several years, Python developers...\n",
       "37    The world of Haskell and functional programmin...\n",
       "40    Images tell stories, and we love Instagram fil...\n",
       "43    Methods are like functions, but different. How...\n",
       "50    Magic methods are a very powerful feature of P...\n",
       "52    Unit, functional, and integration tests are gr...\n",
       "53    When I first began working with the Python Pan...\n",
       "55    Various optimizations made Python 3.6 faster t...\n",
       "57    Exception handling in Python can sometimes fee...\n",
       "58    Assembling all the necessary setup for an appl...\n",
       "60    Bayesian statistics offers robust and flexible...\n",
       "62    Earth imaging satellites, just like our comput...\n",
       "63    Serverless is the latest phase in the evolutio...\n",
       "64    What is it like to interview at 1 technology c...\n",
       "66    Modern genome editing techniques such as CRISP...\n",
       "68    If you want people to use your code you should...\n",
       "69    __slots__ are versatile for certain kinds of u...\n",
       "70    Companies with an artificial-intelligence plan...\n",
       "71    Python is a decades-strong language with a lar...\n",
       "79    Everyone needs to debug code, and it can take ...\n",
       "80    MicroPython is the leanest, meanest full Pytho...\n",
       "81    The statistician John Tukey -- who designed th...\n",
       "83    The software licenses are the permissions over...\n",
       "92    Python's fantastic until it isn't.  This talk ...\n",
       "94    Regular expressions have a reputation as opaqu...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.year==2017) & (df.label==1)]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2017 talks will be used for training and the 2018 talks will we used for predicting. Set the values of `year_labeled` and `year_predict` to appropriate values and print out the values of `description_labeled` and `description_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_labeled=2017\n",
    "year_predict=2018\n",
    "description_labeled = df[df.year==year_labeled]['description']\n",
    "description_predict = df[df.year==year_predict]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Introduction to Text Analysis\n",
    "![text-analysis](text-analysis.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a quick overview of text analysis. Our end goal is to train a machine learning algorithm by making it go through enough documents from each class to recognize the distingusihing characteristics in documents from a particular class. \n",
    "\n",
    "1. *Labeling* - This is the step where the user (i.e. a human) reviews a set of documents and manually classifies them. For our problem, here a Pycon attendee is labeling a talk description from 2017 as \"watch later\"(0) or \"watch now\" (1).\n",
    "1. *Training/Testing split* - In order to test our algorithm, we split parts of our labeled data into training (used to train the algorithm) and testing set (used to test the algorithm).\n",
    "1. *Vectorization & feature extraction* - Since machine learning algorithms deal with numbers rather than words, we vectorize our documents - i.e. we split the documents into individual unique words and count the frequency of their occurance across documents. There are different data normalization is possible at this stage like stop words removal, [lemmatization](https://spacy.io/api/lemmatizer) - but we will skip them for now. Each individual token occurrence frequency (normalized or not) is treated as a feature.\n",
    "1. *Model training* - This is where we build the model.\n",
    "1. *Model testing* - Here we test out the model to see how it is performing against label data as we subject it to the previously set aside test set.\n",
    "1. *Tweak and train* - If our measures are not satisfactory, we will change the parameters that define different aspects of the machine learning algorithm and we will train the model again.\n",
    "1. Once satisfied with the results from the previous step, we are now ready to deploy the model and have new unlabled documents be classified by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Vectorize and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we build the feature set by tokenization, counting and normalization of the bi-grams from the text descriptions of the talk.\n",
    "\n",
    "**tokenizing** strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators\n",
    "\n",
    "**counting** the occurrences of tokens in each document\n",
    "\n",
    "**normalizing** and weighting with diminishing importance tokens that occur in the majority of samples / documents\n",
    "\n",
    "You can find more information on text feature extraction [here](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) and TfidfVectorizer [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Credit\n",
    "Note that we are choosing default value on all parameters for `TfidfVectorizer`. While this is a starting point, for better results we would want to come back and tune them to reduce noise. You can try that after you have taken a first pass through all the exercises. You might consider using [spacy](https://spacy.io/api/lemmatizer) to fine tune the input to `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1 Fit_transform\n",
    "We will use the [fit_transform](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform) method to learn the vocabulary dictionary and return term-document matrix. What should be the input to `fit_transform`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text_labeled = vectorizer.fit_transform(df['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 Inspect the vocabulary\n",
    "Take a look at the vocabulary dictionary that is accessible by calling `vocabulary_` on the `vectorizer`. The stopwords can be accessed using `stop_words_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wring benefit': 15122,\n",
       " 'module briefly': 8610,\n",
       " 'introduce cultivar': 6805,\n",
       " 'load': 7780,\n",
       " 'use access': 14179,\n",
       " 'appium easily': 664,\n",
       " 'python aims': 10535,\n",
       " 'monitors volcanoes': 8642,\n",
       " 'don know': 3993,\n",
       " 'nonetheless compatibility': 8987,\n",
       " 'annoying surprises': 573,\n",
       " 'ways make': 14798,\n",
       " 'problems time': 10113,\n",
       " 'gpus accelerated': 5693,\n",
       " 'choice api': 2006,\n",
       " 'step motivations': 12659,\n",
       " 'mastery': 8179,\n",
       " 'thousands documents': 13530,\n",
       " 'brunch worse': 1567,\n",
       " 'serialization datetime': 11884,\n",
       " 'deployed': 3444,\n",
       " 'integrate documentation': 6669,\n",
       " 'involved analyzing': 6861,\n",
       " 'natural': 8787,\n",
       " 'definitions support': 3367,\n",
       " 'touch early': 13749,\n",
       " 'txt setup': 13967,\n",
       " 'visualization useful': 14657,\n",
       " '30 global': 74,\n",
       " 'alleviate': 444,\n",
       " 'early': 4093,\n",
       " 'example highlight': 4597,\n",
       " 'usually': 14445,\n",
       " 'good helpful': 5651,\n",
       " 'algorithms data': 427,\n",
       " 'hero journey': 6035,\n",
       " 'approximate answer': 799,\n",
       " 'testing stress': 13406,\n",
       " 'project great': 10313,\n",
       " 'cluster': 2105,\n",
       " 'packets': 9391,\n",
       " 'inefficient': 6525,\n",
       " 'bit different': 1459,\n",
       " 'filter': 5094,\n",
       " 'newfound knowledge': 8954,\n",
       " 'running notebook': 11562,\n",
       " 'new library': 8926,\n",
       " 'integration mod_wsgi': 6676,\n",
       " 'document': 3917,\n",
       " '16 python': 22,\n",
       " 'rights software': 11455,\n",
       " 'finally': 5109,\n",
       " 'used facebook': 14272,\n",
       " 'learn step': 7322,\n",
       " 'theano backend': 13453,\n",
       " 'scientific stack': 11705,\n",
       " 'talk listener': 13091,\n",
       " 'pytorch beta': 10762,\n",
       " 'approximate string': 801,\n",
       " 'workhorse': 15028,\n",
       " 'join exploration': 6952,\n",
       " 'structures parallel': 12783,\n",
       " 'pandas seaborn': 9430,\n",
       " 'licenses favored': 7534,\n",
       " 'ended': 4371,\n",
       " 'don confidence': 3989,\n",
       " 'microcontroller': 8371,\n",
       " 'level complex': 7432,\n",
       " 'talk minor': 13098,\n",
       " 'given concepts': 5588,\n",
       " 'ability process': 139,\n",
       " 'decorators': 3328,\n",
       " 'returns': 11403,\n",
       " 'interested results': 6719,\n",
       " 'assume': 922,\n",
       " 'wondering': 14946,\n",
       " 'challenges effective': 1910,\n",
       " 'piles mocks': 9674,\n",
       " 'wonderful command': 14942,\n",
       " 'receive python': 11015,\n",
       " 'years great': 15240,\n",
       " 'consider fast': 2647,\n",
       " '28885213 including': 69,\n",
       " 'way future': 14764,\n",
       " 'wisely': 14920,\n",
       " 'radar scattering': 10855,\n",
       " 'today complex': 13647,\n",
       " 'tools combine': 13704,\n",
       " 'python impossible': 10631,\n",
       " 'use dictionary': 14197,\n",
       " 'similar movies': 12097,\n",
       " 'interfaces': 6739,\n",
       " 'method generating': 8327,\n",
       " 'writers like': 15152,\n",
       " 'taking beautiful': 13018,\n",
       " 'applications use': 742,\n",
       " 'authors produced': 1038,\n",
       " 'discuss asyncio': 3794,\n",
       " 'easier mathematical': 4114,\n",
       " 'module ll': 8613,\n",
       " 'discovered': 3789,\n",
       " 'understanding components': 14067,\n",
       " 'fuzzy searching': 5464,\n",
       " 'familiarize': 4929,\n",
       " 'search functions': 11772,\n",
       " 'helps choose': 6028,\n",
       " 'bytecode understand': 1723,\n",
       " 'flexible': 5189,\n",
       " 'multidimensional': 8695,\n",
       " 'scipy used': 11727,\n",
       " 'learned using': 7336,\n",
       " 'resources build': 11324,\n",
       " 'operators': 9212,\n",
       " 'going great': 5632,\n",
       " 'corpus consider': 2817,\n",
       " 'compare': 2385,\n",
       " 'want maybe': 14715,\n",
       " 'extensively': 4836,\n",
       " 'techniques leveling': 13254,\n",
       " 'speed method': 12462,\n",
       " 'shared interacts': 12017,\n",
       " 'edges': 4196,\n",
       " 'talk shall': 13119,\n",
       " 'easy forget': 4153,\n",
       " 'focus': 5203,\n",
       " 'life quite': 7547,\n",
       " 'pythonista bayesians': 10759,\n",
       " 'contributions': 2741,\n",
       " 'functions bunch': 5421,\n",
       " 'big helps': 1419,\n",
       " 'category': 1850,\n",
       " 'inputs': 6588,\n",
       " 'high scale': 6058,\n",
       " 'library authors': 7496,\n",
       " 'huge': 6166,\n",
       " 'compatible numpy': 2406,\n",
       " 'twice year': 13956,\n",
       " 'uses cuda': 14379,\n",
       " 'markov chain': 8166,\n",
       " 'midiutil': 8392,\n",
       " 'packages': 9370,\n",
       " 'stepping': 12662,\n",
       " 'exploration dimensional': 4755,\n",
       " 'spectacular': 12451,\n",
       " 'creating pictures': 2951,\n",
       " 'order truly': 9263,\n",
       " 'data improve': 3115,\n",
       " 'dose python': 4008,\n",
       " 'news problems': 8958,\n",
       " 'learn just': 7293,\n",
       " 'hidden': 6042,\n",
       " 'developers make': 3592,\n",
       " 'feature talk': 4999,\n",
       " 'way python': 14781,\n",
       " 'issues disabling': 6895,\n",
       " 'components project': 2481,\n",
       " 'loop worker': 7876,\n",
       " 'data data': 3097,\n",
       " 'job ll': 6943,\n",
       " 'pyspark': 10521,\n",
       " 'talk talk': 13130,\n",
       " 'handle': 5854,\n",
       " 'eager': 4091,\n",
       " 'jukka': 6971,\n",
       " 'poorly': 9806,\n",
       " 'proven': 10401,\n",
       " 'users expert': 14350,\n",
       " 'website': 14842,\n",
       " 'guy starts': 5821,\n",
       " 'assist determining': 916,\n",
       " 'deploy app': 3436,\n",
       " 'robustness': 11496,\n",
       " 'ngrok': 8961,\n",
       " 'identify': 6233,\n",
       " 'involves model': 6869,\n",
       " 'metric dashboard': 8357,\n",
       " 'text did': 13436,\n",
       " 'way set': 14786,\n",
       " 'postgres': 9853,\n",
       " 'common granted': 2326,\n",
       " 'members reference': 8269,\n",
       " 'test decide': 13345,\n",
       " 'genetic causes': 5539,\n",
       " 'written worker': 15190,\n",
       " 'auditors alike': 1021,\n",
       " 'latest': 7216,\n",
       " 'used functionality': 14277,\n",
       " 'computing science': 2543,\n",
       " 'specified': 12447,\n",
       " 'right': 11439,\n",
       " 'count thou': 2842,\n",
       " 'main stream': 7969,\n",
       " 'perform': 9581,\n",
       " 'duplicated': 4078,\n",
       " 'import time': 6344,\n",
       " 'api create': 609,\n",
       " 'contact': 2691,\n",
       " 'recover having': 11068,\n",
       " 'extends': 4822,\n",
       " 'll interface': 7730,\n",
       " 'lot different': 7889,\n",
       " 'versions website': 14616,\n",
       " 'harness power': 5917,\n",
       " 'receive': 11013,\n",
       " 'hmc variational': 6096,\n",
       " 'way powerful': 14777,\n",
       " 'architecture makes': 823,\n",
       " 'schema approach': 11680,\n",
       " 'states world': 12608,\n",
       " 'data structure': 3168,\n",
       " 'masterpiece come': 8178,\n",
       " 'tools libraries': 13717,\n",
       " 'cuda related': 2990,\n",
       " 'restructuredtext': 11367,\n",
       " 'world complex': 15062,\n",
       " 'psychological': 10441,\n",
       " 'facilitates': 4877,\n",
       " 'write confident': 15127,\n",
       " 'developers talk': 3599,\n",
       " 'game genie': 5476,\n",
       " 'write software': 15146,\n",
       " 'introduce big': 6802,\n",
       " 'perfect': 9576,\n",
       " 'license': 7527,\n",
       " 'surprising': 12916,\n",
       " 'humans heuristics': 6189,\n",
       " 'publication date': 10447,\n",
       " 'google stripe': 5669,\n",
       " 'exciting': 4637,\n",
       " 'build program': 1624,\n",
       " 'kinds uses': 7048,\n",
       " 'sample monolithic': 11611,\n",
       " 'thought': 13520,\n",
       " 'handle email': 5859,\n",
       " 'novel techniques': 9025,\n",
       " 'united states': 14105,\n",
       " 'experience having': 4699,\n",
       " 'deploying': 3447,\n",
       " 'understanding systems': 14072,\n",
       " 'email based': 4281,\n",
       " 'used make': 14283,\n",
       " 'supported python': 12890,\n",
       " 'finally look': 5116,\n",
       " 'example hybrid': 4598,\n",
       " 'working examples': 15034,\n",
       " 'lets run': 7423,\n",
       " 'featured': 5001,\n",
       " 'bayesian statistics': 1283,\n",
       " 'forms': 5267,\n",
       " 'logs instrumenting': 7825,\n",
       " 'enable': 4318,\n",
       " '2020 python': 58,\n",
       " 'apps shine': 805,\n",
       " 'paths improving': 9513,\n",
       " 'oauth2 openidconnect': 9084,\n",
       " 'sure witness': 12905,\n",
       " 'apply techniques': 757,\n",
       " 'inside thousands': 6598,\n",
       " 'called model': 1762,\n",
       " 'stack make': 12522,\n",
       " 'basic concepts': 1240,\n",
       " 'checker bolt': 1981,\n",
       " 'right form': 11443,\n",
       " 'non': 8979,\n",
       " 'share ideas': 12010,\n",
       " 'necessary follow': 8808,\n",
       " 'build reusable': 1629,\n",
       " 'solve problem': 12329,\n",
       " 'slow integration': 12221,\n",
       " 'explain license': 4733,\n",
       " 'like want': 7604,\n",
       " 'relevant problem': 11183,\n",
       " 'non compatible': 8981,\n",
       " 'hard page': 5899,\n",
       " 'disaster': 3774,\n",
       " 'performance ll': 9596,\n",
       " 'applications doing': 716,\n",
       " 'share practical': 12014,\n",
       " 'happens setting': 5891,\n",
       " 'career': 1800,\n",
       " 'project aims': 10304,\n",
       " 'aware datetimes': 1142,\n",
       " 'apis talk': 645,\n",
       " 'grant use': 5709,\n",
       " 'humanization examining': 6185,\n",
       " 'fashion used': 4949,\n",
       " 'stuff': 12795,\n",
       " 'testing manual': 13391,\n",
       " 'development having': 3617,\n",
       " 'questions come': 10806,\n",
       " 'illustrates python': 6263,\n",
       " 'work mature': 14981,\n",
       " 'speak different': 12411,\n",
       " 'perfectly good': 9580,\n",
       " 'latest trends': 7222,\n",
       " 'marketing': 8162,\n",
       " 'provides great': 10426,\n",
       " 'reason bytecode': 11001,\n",
       " 'sketch better': 12189,\n",
       " 'distant place': 3848,\n",
       " 'scratch looks': 11738,\n",
       " 'finishing': 5136,\n",
       " 'evaluated expressions': 4530,\n",
       " 'including weird': 6460,\n",
       " 'moustaches aquiver': 8672,\n",
       " 'people started': 9552,\n",
       " 'workarounds problems': 15005,\n",
       " 'data messy': 3130,\n",
       " 'daily': 3061,\n",
       " 'untested': 14137,\n",
       " 'making machines': 8085,\n",
       " 'mean code': 8228,\n",
       " 'memory reallocations': 8279,\n",
       " 'allowing': 460,\n",
       " 'process write': 10145,\n",
       " 'linear workflows': 7640,\n",
       " 'developer traits': 3575,\n",
       " 'cython numba': 3058,\n",
       " 'social good': 12266,\n",
       " 'way make': 14773,\n",
       " 'nginx': 8959,\n",
       " 'ubiquitous': 14012,\n",
       " 'address': 300,\n",
       " 'construction': 2680,\n",
       " 'analyze manage': 539,\n",
       " 'service highly': 11928,\n",
       " 'starting python': 12591,\n",
       " 'sly': 12233,\n",
       " 'half': 5835,\n",
       " 'large need': 7190,\n",
       " 'changes': 1937,\n",
       " 'dedicated': 3336,\n",
       " 'typeerror crash': 13986,\n",
       " 'checking code': 1984,\n",
       " 'click fuzzyfind': 2071,\n",
       " 'small army': 12237,\n",
       " 'traditional mapreduce': 13790,\n",
       " '33 python': 82,\n",
       " 'web application': 14816,\n",
       " 'multiple years': 8709,\n",
       " 'pattern': 9516,\n",
       " 'manage deploy': 8094,\n",
       " 'imperfect place': 6293,\n",
       " 'looks easy': 7870,\n",
       " 'library building': 7498,\n",
       " '__slots__ work': 122,\n",
       " 'numpy cases': 9068,\n",
       " 'readable providing': 10938,\n",
       " 'tests useless': 13427,\n",
       " 'systems fail': 12977,\n",
       " 'apache spark': 599,\n",
       " 'field': 5059,\n",
       " 'struggle fully': 12788,\n",
       " 'fundamental': 5435,\n",
       " 'discuss difference': 3799,\n",
       " 'run faster': 11539,\n",
       " 'stories': 12694,\n",
       " 'requests gui': 11266,\n",
       " 'stream data': 12725,\n",
       " 'analyze data': 537,\n",
       " 'neural sequence': 8898,\n",
       " 'perspective': 9631,\n",
       " 'frameworks designing': 5326,\n",
       " 'talk focused': 13072,\n",
       " 'surprise recommendation': 12910,\n",
       " 'language like': 7150,\n",
       " 'quickly hack': 10826,\n",
       " 'letting': 7427,\n",
       " 'problem solutions': 10080,\n",
       " 'code improve': 2151,\n",
       " 'distribute python': 3856,\n",
       " 'recently impossible': 11024,\n",
       " 'device': 3638,\n",
       " 'scripts instead': 11755,\n",
       " 'terms machine': 13331,\n",
       " 'tooling order': 13687,\n",
       " 'wrangling statistical': 15108,\n",
       " 'partial application': 9466,\n",
       " 'invisible products': 6856,\n",
       " 'systemd solve': 12964,\n",
       " 'emerging pure': 4298,\n",
       " 'future reliability': 5455,\n",
       " 'carries': 1809,\n",
       " 'worked performance': 15010,\n",
       " 'readily interpretable': 10940,\n",
       " 'bootstrap apache': 1495,\n",
       " 'inspiring new': 6615,\n",
       " 'aspects uncertainty': 902,\n",
       " 'underlie': 14033,\n",
       " 'choices': 2008,\n",
       " 'errors detect': 4493,\n",
       " 'syntax tree': 12962,\n",
       " 'doom small': 4003,\n",
       " 'translation catalogs': 13841,\n",
       " 'hasn final': 5925,\n",
       " 'discribing data': 3792,\n",
       " 'used tools': 14298,\n",
       " 'protocols provides': 10392,\n",
       " 'good pandas': 5656,\n",
       " 'data giving': 3112,\n",
       " 'modular deep': 8602,\n",
       " 'overcome problems': 9324,\n",
       " 'case ll': 1820,\n",
       " 'language know': 7146,\n",
       " 'hypothesis': 6210,\n",
       " 'reflects company': 11106,\n",
       " 'libraries teach': 7485,\n",
       " 'play': 9758,\n",
       " 'famously new': 4938,\n",
       " 'model said': 8530,\n",
       " 'things software': 13484,\n",
       " 'considering trade': 2662,\n",
       " 'https www': 6165,\n",
       " 'examine effectively': 4590,\n",
       " 'data answer': 3081,\n",
       " 'appium': 663,\n",
       " 'thought battle': 13521,\n",
       " 'time team': 13594,\n",
       " 'belly': 1344,\n",
       " 'purpose art': 10459,\n",
       " 'tag release': 13002,\n",
       " 'mount': 8669,\n",
       " 'opportunity': 9216,\n",
       " 'bars talk': 1215,\n",
       " 've heard': 14543,\n",
       " 'embedded computer': 4288,\n",
       " 'wanted conference': 14724,\n",
       " 'libraries compatible': 7464,\n",
       " 'interpreters python': 6782,\n",
       " 'messages manipulate': 8303,\n",
       " 'framing bugs': 5336,\n",
       " 'named tuples': 8763,\n",
       " 'based asyncio': 1225,\n",
       " 'world problems': 15077,\n",
       " 'raise valueerror': 10859,\n",
       " 'beazley ply': 1303,\n",
       " 'member project': 8265,\n",
       " 'space telescope': 12389,\n",
       " 'plenty example': 9778,\n",
       " 'outlines': 9306,\n",
       " 'pandas documentation': 9424,\n",
       " 'dependencies better': 3423,\n",
       " 'meltdowns': 8262,\n",
       " 'lack': 7119,\n",
       " 'released': 11171,\n",
       " 'acquired variety': 241,\n",
       " 'preprocessing': 9961,\n",
       " 'imperfections software': 6297,\n",
       " 'transferring traffic': 13820,\n",
       " 'like type': 7601,\n",
       " 'behave teams': 1330,\n",
       " 'gaussian processes': 5497,\n",
       " 'nasa': 8778,\n",
       " 'useful remember': 14310,\n",
       " 'functions cloud': 5422,\n",
       " 'ways cultivate': 14794,\n",
       " 'guidelines building': 5814,\n",
       " 'psychological reasons': 10442,\n",
       " 'building production': 1660,\n",
       " 'surprisingly easy': 12920,\n",
       " 'ideal': 6218,\n",
       " 'mentioned': 8284,\n",
       " 'times profiling': 13617,\n",
       " 'critique peers': 2975,\n",
       " 'results outputs': 11383,\n",
       " 'offers robust': 9133,\n",
       " '_format_email returns': 124,\n",
       " 'referred': 11101,\n",
       " 'called': 1756,\n",
       " 'copyrighted software': 2801,\n",
       " 'people looked': 9545,\n",
       " 'conference conference': 2587,\n",
       " 'annealing quantum': 565,\n",
       " 'need designed': 8821,\n",
       " 'headed expect': 5949,\n",
       " 'correct inputs': 2825,\n",
       " 'consuming': 2689,\n",
       " 'delegate rest': 3373,\n",
       " 'freeze': 5349,\n",
       " 'constraints': 2675,\n",
       " 'started path': 12581,\n",
       " 'concept exception': 2549,\n",
       " 'postgresql': 9855,\n",
       " 'correct solution': 2826,\n",
       " 'discover upgrade': 3786,\n",
       " 'recovery': 11070,\n",
       " 'debugger consider': 3275,\n",
       " 'testing ci': 13372,\n",
       " 'presentation make': 9973,\n",
       " 'script runner': 11748,\n",
       " 'talk combined': 13046,\n",
       " 'building robots': 1665,\n",
       " 'want analyze': 14706,\n",
       " 'forget': 5249,\n",
       " 'ecosystem means': 4186,\n",
       " 'entirely ll': 4446,\n",
       " 'common approaches': 2318,\n",
       " 'point': 9789,\n",
       " 'architecture required': 824,\n",
       " 'tools software': 13729,\n",
       " 'pre ascii': 9933,\n",
       " 'written python': 15186,\n",
       " 'considered relationships': 2659,\n",
       " 'background': 1170,\n",
       " 'realistic reliable': 10974,\n",
       " 'form just': 5253,\n",
       " 'collaboration applies': 2236,\n",
       " 'data model': 3134,\n",
       " 'complex use': 2451,\n",
       " 'prevent minimize': 9994,\n",
       " 'trying distribute': 13922,\n",
       " 'learn designed': 7279,\n",
       " 'calculations talk': 1749,\n",
       " 'translating ll': 13839,\n",
       " 'looks start': 7871,\n",
       " 'code 7370': 2110,\n",
       " 'services': 11938,\n",
       " 'inspired': 6609,\n",
       " 'evident use': 4570,\n",
       " 'myriad': 8751,\n",
       " 'ones handle': 9160,\n",
       " 'course': 2854,\n",
       " 'stacking demonstrate': 12528,\n",
       " 'programming right': 10281,\n",
       " 'instructions talk': 6656,\n",
       " 'compositional semantics': 2489,\n",
       " 'health': 5950,\n",
       " 'uncover secret': 14026,\n",
       " 'edits production': 4210,\n",
       " 'cable': 1728,\n",
       " 'explain': 4729,\n",
       " 'language build': 7140,\n",
       " 'model coverage': 8503,\n",
       " 'application available': 668,\n",
       " 'comprehensions python': 2494,\n",
       " 'ubiquitous possible': 14013,\n",
       " 'evolution cloud': 4572,\n",
       " 'built python': 1691,\n",
       " 'mod_wsgi years': 8492,\n",
       " 'custom corpus': 3031,\n",
       " 'application couldn': 677,\n",
       " 'arduous tasks': 835,\n",
       " 'tensorflow theano': 13322,\n",
       " 'ongoing': 9165,\n",
       " 'does support': 3960,\n",
       " 'cloud vendors': 2102,\n",
       " 'scripts write': 11760,\n",
       " 'years make': 15245,\n",
       " 'advent': 337,\n",
       " 'reactivex': 10917,\n",
       " 'choose kind': 2013,\n",
       " 'inside box': 6596,\n",
       " 'alleviate challenges': 445,\n",
       " 'things use': 13487,\n",
       " 'talk': 13028,\n",
       " 'model interface': 8520,\n",
       " 'complex doesn': 2442,\n",
       " 'django framework': 3902,\n",
       " 'deployment academic': 3453,\n",
       " 'backfired': 1168,\n",
       " 'extensibility improve': 4827,\n",
       " 'better model': 1404,\n",
       " 'ai plays': 394,\n",
       " 'interface callers': 6728,\n",
       " 'regarded': 11109,\n",
       " 'make comparisons': 8014,\n",
       " 'based kafka': 1231,\n",
       " 'principle example': 10015,\n",
       " 'software topics': 12300,\n",
       " 'leaders stepping': 7254,\n",
       " 'discover': 3780,\n",
       " 'science math': 11694,\n",
       " 'theorized': 13459,\n",
       " 'help various': 6009,\n",
       " 'execute code': 4641,\n",
       " 'behaviours': 1342,\n",
       " 'faster safer': 4970,\n",
       " 'end life': 4359,\n",
       " 'environments internet': 4473,\n",
       " 'draw key': 4033,\n",
       " 'record keeping': 11063,\n",
       " 'module pypi': 8617,\n",
       " 'common fields': 2325,\n",
       " 'systems ask': 12969,\n",
       " 'user developer': 14325,\n",
       " 'slip': 12211,\n",
       " 'powered': 9881,\n",
       " 'evaluation framework': 4541,\n",
       " 'lead': 7247,\n",
       " 'like don': 7570,\n",
       " 'production hundreds': 10199,\n",
       " 'rabbit hole': 10843,\n",
       " 'computers inside': 2531,\n",
       " 'data substantially': 3170,\n",
       " 'culture culture': 3001,\n",
       " 'functional programming': 5410,\n",
       " 'll real': 7753,\n",
       " 'eventual consistency': 4562,\n",
       " 'principle': 10013,\n",
       " 'extend': 4815,\n",
       " 'planned': 9735,\n",
       " 'reach scientific': 10914,\n",
       " 'trans': 13817,\n",
       " 'ideal edge': 6219,\n",
       " 'flake8 pylint': 5171,\n",
       " 'calculations slow': 1748,\n",
       " 'express': 4798,\n",
       " 'iv': 6916,\n",
       " 'data work': 3180,\n",
       " 'pieces ensuring': 9671,\n",
       " 'explanation eda': 4748,\n",
       " 'networks using': 8894,\n",
       " 'given': 5587,\n",
       " 'cases terrible': 1835,\n",
       " 'central string': 1879,\n",
       " 'ideas evolved': 6226,\n",
       " 'keeping enthusiasm': 7016,\n",
       " 'representation box': 11250,\n",
       " 'agent interpret': 365,\n",
       " 'compiled languages': 2419,\n",
       " 'accelerated cuda': 182,\n",
       " 'number powerful': 9049,\n",
       " 'overhead': 9327,\n",
       " 'operates': 9195,\n",
       " 'site': 12168,\n",
       " 'use process': 14230,\n",
       " 'wildman whitehouse': 14908,\n",
       " 'techniques shortcomings': 13261,\n",
       " 'love instagram': 7910,\n",
       " 'train': 13797,\n",
       " 'generated': 5519,\n",
       " 'copy': 2796,\n",
       " 'config': 2605,\n",
       " 'putting attendee': 10471,\n",
       " 'optimize constant': 9233,\n",
       " 'pager': 9400,\n",
       " 'way organize': 14776,\n",
       " 'development small': 3628,\n",
       " 'll example': 7719,\n",
       " 'level compassionate': 7431,\n",
       " 'playing': 9765,\n",
       " 'unlike traditional': 14122,\n",
       " 'benefits understandability': 1368,\n",
       " 'avoid common': 1120,\n",
       " 'minke extends': 8425,\n",
       " 'pygments click': 10495,\n",
       " 'bucket management': 1571,\n",
       " 'bugs best': 1581,\n",
       " 'tradeoffs using': 13786,\n",
       " 'compiled talk': 2420,\n",
       " 'improved contribution': 6393,\n",
       " 'better talk': 1407,\n",
       " 'work way': 14998,\n",
       " 'friendly direction': 5362,\n",
       " 'program': 10241,\n",
       " 'talk teach': 13131,\n",
       " 'bunch': 1695,\n",
       " 'talk work': 13146,\n",
       " 'scopes': 11728,\n",
       " 'context data': 2713,\n",
       " 'partial': 9465,\n",
       " 'community big': 2363,\n",
       " 'browsable': 1562,\n",
       " 'interact event': 6704,\n",
       " 'showcase': 12066,\n",
       " 'built conference': 1679,\n",
       " 'statistics offers': 12637,\n",
       " 'pull requests': 10453,\n",
       " 'outside training': 9322,\n",
       " 'regardless text': 11114,\n",
       " 'calculations': 1746,\n",
       " 'cover simple': 2876,\n",
       " 'dependencies requirements': 3426,\n",
       " 'run phone': 11545,\n",
       " 'objects api': 9098,\n",
       " 'look archaic': 7843,\n",
       " 'rnn called': 11470,\n",
       " 'analytics stream': 531,\n",
       " 'analytics process': 530,\n",
       " 'heard': 5963,\n",
       " 'productive api': 10213,\n",
       " 'automate steps': 1047,\n",
       " 'use dictionaries': 14196,\n",
       " 'launhced': 7226,\n",
       " 'applied': 747,\n",
       " 'perceptual humanization': 9575,\n",
       " 'app run': 654,\n",
       " 'variational inference': 14502,\n",
       " 'assuming': 929,\n",
       " 'practice intend': 9917,\n",
       " 'code run': 2179,\n",
       " 'seaborn': 11761,\n",
       " 'bad rap': 1191,\n",
       " 'advent probabilistic': 340,\n",
       " 'rest framework': 11358,\n",
       " 'object models': 9089,\n",
       " 'musician looking': 8735,\n",
       " 'mutation': 8738,\n",
       " 'dimensional space': 3746,\n",
       " 'mp3s': 8687,\n",
       " 'nvidia jetson': 9078,\n",
       " 'common secret': 2337,\n",
       " 'frameworks think': 5332,\n",
       " '2003': 35,\n",
       " 'dictionaries values': 3660,\n",
       " 'python aspects': 10541,\n",
       " 'ingesting formal': 6562,\n",
       " 'py just': 10479,\n",
       " 'frameworks existed': 5327,\n",
       " 'does converge': 3950,\n",
       " 'rely converts': 11199,\n",
       " 'emulator': 4315,\n",
       " 'incompatibility': 6474,\n",
       " 'preprocessed': 9959,\n",
       " 'helps make': 6030,\n",
       " 'apps juggling': 804,\n",
       " 'integers writing': 6666,\n",
       " 'really going': 10994,\n",
       " 'approach working': 782,\n",
       " 'entirely': 4445,\n",
       " 'working matching': 15037,\n",
       " 'computer': 2519,\n",
       " 'monolithic application': 8647,\n",
       " 'assembling necessary': 904,\n",
       " 'oft underdeveloped': 9148,\n",
       " 'hastings gilectomy': 5930,\n",
       " 'created jukka': 2941,\n",
       " 'send': 11843,\n",
       " 'sort outreach': 12354,\n",
       " 'work existing': 14970,\n",
       " 'using advent': 14388,\n",
       " 'want things': 14720,\n",
       " 'review varied': 11417,\n",
       " 'comparison sorting': 2393,\n",
       " 'allow change': 453,\n",
       " 'machine explore': 7937,\n",
       " 'apache': 595,\n",
       " 'variable annotations': 14493,\n",
       " 'applying': 759,\n",
       " 'handler process': 5868,\n",
       " 'guess money': 5801,\n",
       " 'work efficiently': 14969,\n",
       " 'projects python': 10352,\n",
       " 'tools additional': 13699,\n",
       " 'orchestrating': 9250,\n",
       " 'novelties language': 9029,\n",
       " 'value writing': 14482,\n",
       " 'renaissance ml': 11223,\n",
       " 'respectively neural': 11335,\n",
       " 'python bytecode': 10557,\n",
       " 'ready share': 10954,\n",
       " 'badly': 1193,\n",
       " 'music catering': 8720,\n",
       " 'tdd help': 13192,\n",
       " 'certain types': 1887,\n",
       " 'projects want': 10354,\n",
       " 'ecosystem python': 4187,\n",
       " 'devices vendors': 3650,\n",
       " 'caching': 1737,\n",
       " 'shown step': 12074,\n",
       " 'games': 5479,\n",
       " 'smallest python': 12247,\n",
       " 'bring python': 1550,\n",
       " 'benefits': 1362,\n",
       " 'opcodes': 9172,\n",
       " 'function calls': 5399,\n",
       " 'platform service': 9747,\n",
       " 'monitor device': 8632,\n",
       " 'places right': 9725,\n",
       " 'act inspired': 243,\n",
       " 'versions package': 14611,\n",
       " 'technology company': 13274,\n",
       " 'level sequence': 7439,\n",
       " 'offering greatly': 9129,\n",
       " 'ago contributing': 383,\n",
       " 'abstract base': 160,\n",
       " 'solutions supercharging': 12320,\n",
       " 'official forum': 9140,\n",
       " 'devices dive': 3644,\n",
       " 'health built': 5951,\n",
       " 'create beautiful': 2922,\n",
       " 'fewer': 5057,\n",
       " 'filter aggregate': 5096,\n",
       " 'abstract complexity': 161,\n",
       " 'spend attendees': 12471,\n",
       " 'associate': 917,\n",
       " 'python scientific': 10705,\n",
       " 'drawing': 4036,\n",
       " 'reduced': 11085,\n",
       " 'situations': 12179,\n",
       " 'pytest ve': 10528,\n",
       " 'tasks uniquely': 13183,\n",
       " 'quantities labeled': 10787,\n",
       " 'tensor computation': 13312,\n",
       " 'redesign run': 11076,\n",
       " 'worker': 15015,\n",
       " 'stop': 12677,\n",
       " 'characters': 1953,\n",
       " 'discover practical': 3783,\n",
       " 'access bin': 186,\n",
       " 'sure': 12904,\n",
       " 'rpython': 11522,\n",
       " 'primitives demonstrate': 10011,\n",
       " 'available party': 1096,\n",
       " 'bridge': 1536,\n",
       " 'requiring': 11299,\n",
       " 'guidance': 5806,\n",
       " 'artificial intelligence': 876,\n",
       " 'simply don': 12138,\n",
       " 'try discuss': 13914,\n",
       " 'movement dealing': 8674,\n",
       " 'interface designing': 6730,\n",
       " 'tact': 12999,\n",
       " 'ddos logging': 3252,\n",
       " 'units': 14106,\n",
       " 'great lineup': 5749,\n",
       " 'measure performance': 8251,\n",
       " 'active users': 257,\n",
       " 'knows lot': 7107,\n",
       " 'binary module': 1445,\n",
       " 'geospatial data': 5557,\n",
       " 'lazy loading': 7245,\n",
       " 'loop': 7874,\n",
       " 'collaboration automated': 2237,\n",
       " 'application run': 694,\n",
       " 'world today': 15086,\n",
       " 'actual': 264,\n",
       " 'intermediate python': 6750,\n",
       " 'produced': 10177,\n",
       " 'tool represent': 13681,\n",
       " 'struggle': 12787,\n",
       " '523': 101,\n",
       " 'function uses': 5406,\n",
       " 'feature python': 4997,\n",
       " 'process considerate': 10121,\n",
       " 'greatest machines': 5764,\n",
       " 'passes': 9493,\n",
       " 'parsers grammars': 9462,\n",
       " 'watch': 14744,\n",
       " 'models including': 8562,\n",
       " 'trip': 13882,\n",
       " 'bin': 1438,\n",
       " 'sideburns gentlemen': 12084,\n",
       " '300kb memory': 80,\n",
       " 'learn specific': 7321,\n",
       " 'talk clarify': 13044,\n",
       " 'effort project': 4257,\n",
       " 'dict': 3655,\n",
       " 'code backend': 2118,\n",
       " 'presentation tools': 9974,\n",
       " 'recognition simple': 11037,\n",
       " '3000 pages': 78,\n",
       " 'practicing': 9930,\n",
       " 'raspberry': 10902,\n",
       " 'teams write': 13225,\n",
       " 'contribution process': 2740,\n",
       " 'nuance': 9036,\n",
       " 'easier handle': 4113,\n",
       " 'broad community': 1557,\n",
       " 'high overhead': 6055,\n",
       " 'possess': 9833,\n",
       " 'fixes bugs': 5164,\n",
       " 'provide api': 10405,\n",
       " 'deploying python': 3448,\n",
       " 'make results': 8046,\n",
       " 'gilectomy project': 5582,\n",
       " 'building pipeline': 1657,\n",
       " 'time world': 13604,\n",
       " 'monte': 8651,\n",
       " 'attempt': 982,\n",
       " 'components maintained': 2478,\n",
       " 'steve dower': 12674,\n",
       " 'hard problem': 5900,\n",
       " 'turn public': 13932,\n",
       " 'predicting traffic': 9946,\n",
       " 'moustaches': 8671,\n",
       " 'mighty garbage': 8396,\n",
       " 'loading': 7784,\n",
       " 'explain example': 4731,\n",
       " 'makes application': 8065,\n",
       " 'avg': 1117,\n",
       " 'dataclasses': 3197,\n",
       " '10000': 13,\n",
       " 'secret': 11792,\n",
       " 'project computation': 10309,\n",
       " 'advanced': 324,\n",
       " 'scientists': 11711,\n",
       " 'steps involved': 12669,\n",
       " 'going files': 5631,\n",
       " 'mathematical computation': 8192,\n",
       " 'use sound': 14243,\n",
       " 'network architecture': 8876,\n",
       " 'knows': 7105,\n",
       " 'develop codebase': 3548,\n",
       " 'process upgrading': 10144,\n",
       " 'pymalloc': 10501,\n",
       " 'exposed use': 4793,\n",
       " 'support number': 12883,\n",
       " 'programming async': 10267,\n",
       " 'forum cupy': 5286,\n",
       " '000 python': 2,\n",
       " 'charts': 1961,\n",
       " 'talk focus': 13071,\n",
       " 'fast numerical': 4959,\n",
       " 'overturn fate': 9337,\n",
       " 'project talk': 10328,\n",
       " 'statistical modeling': 12625,\n",
       " 'slow growth': 12220,\n",
       " 'game plenty': 5478,\n",
       " 'value decomposition': 14479,\n",
       " 'environments cpython': 4472,\n",
       " 'auditability': 1015,\n",
       " 'characteristics model': 1952,\n",
       " 'useful building': 14301,\n",
       " 'development longer': 3619,\n",
       " 'supercharging': 12864,\n",
       " 'solution inverse': 12310,\n",
       " 'test driven': 13347,\n",
       " 'crop time': 2979,\n",
       " 'talk programmer': 13107,\n",
       " 'corpora huge': 2815,\n",
       " 'like heroku': 7578,\n",
       " 'crash': 2917,\n",
       " 'run web': 11553,\n",
       " 'fabric terraform': 4856,\n",
       " 'fast calls': 4951,\n",
       " 'documentation tools': 3933,\n",
       " 'evolution': 4571,\n",
       " 'work pacemakers': 14984,\n",
       " 'use programs': 14232,\n",
       " 'extension basics': 4829,\n",
       " 'code explain': 2144,\n",
       " 'complex real': 2447,\n",
       " 'state presenting': 12601,\n",
       " 'fight upgrade': 5065,\n",
       " 'extension': 4828,\n",
       " 'exist': 4654,\n",
       " 'parsers': 9460,\n",
       " 'won': 14924,\n",
       " 'footprint talk': 5242,\n",
       " 'bird feeder': 1452,\n",
       " 'techniques refactoring': 13258,\n",
       " 'aim': 396,\n",
       " 'spatial relations': 12407,\n",
       " 'map information': 8149,\n",
       " 'surprise': 12908,\n",
       " 'different design': 3702,\n",
       " 'airbags': 410,\n",
       " 'models uses': 8573,\n",
       " 'keys': 7041,\n",
       " 'proved': 10399,\n",
       " 'august': 1027,\n",
       " 'notebook covers': 9002,\n",
       " 'learn matplotlib': 7300,\n",
       " 've got': 14542,\n",
       " 'productive tdd': 10219,\n",
       " 'dirtied': 3760,\n",
       " 'adding test': 286,\n",
       " 'task runner': 13169,\n",
       " 'mentor easy': 8288,\n",
       " 'modern packaging': 8589,\n",
       " 'code cleaner': 2127,\n",
       " 'api wrapper': 636,\n",
       " 'structure configure': 12774,\n",
       " 'confusion python': 2626,\n",
       " 'explains key': 4744,\n",
       " 'python scripts': 10706,\n",
       " 'xml rpcs': 15218,\n",
       " 'document python': 3918,\n",
       " 'mypy static': 8748,\n",
       " 'people means': 9546,\n",
       " 'data types': 3174,\n",
       " 'python libraries': 10645,\n",
       " 'recommending': 11053,\n",
       " 'oscar box': 9295,\n",
       " 'setting talk': 11986,\n",
       " 'finally learn': 5114,\n",
       " 'model united': 8537,\n",
       " 'software dependencies': 12277,\n",
       " 'code python': 2173,\n",
       " 'jetson embedded': 6941,\n",
       " 'ramparts': 10862,\n",
       " '2d arcade': 71,\n",
       " 'life better': 7540,\n",
       " 'current': 3014,\n",
       " 'design using': 3492,\n",
       " 'remember learned': 11208,\n",
       " 'using rust': 14431,\n",
       " 'ones systems': 9163,\n",
       " 'job talked': 6945,\n",
       " 'learn importance': 7288,\n",
       " 'transforming converting': 13828,\n",
       " 'using __file__': 14387,\n",
       " 'rarely resources': 10901,\n",
       " 'platform nvidia': 9744,\n",
       " 'methods allow': 8338,\n",
       " 'ahead moving': 390,\n",
       " 'piles': 9673,\n",
       " 'sensible output': 11856,\n",
       " 'enable write': 4324,\n",
       " ...}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `get_feature_names` function on the Tfidf `vectorizer` to get the features (terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurrences</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10529</th>\n",
       "      <td>8.321895</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077</th>\n",
       "      <td>4.995324</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7698</th>\n",
       "      <td>4.851871</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13028</th>\n",
       "      <td>4.291750</td>\n",
       "      <td>talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>4.186579</td>\n",
       "      <td>code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14177</th>\n",
       "      <td>3.030154</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>2.635332</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>2.484063</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14386</th>\n",
       "      <td>2.476606</td>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13697</th>\n",
       "      <td>2.421009</td>\n",
       "      <td>tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7337</th>\n",
       "      <td>2.347013</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13368</th>\n",
       "      <td>2.319585</td>\n",
       "      <td>testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>2.273278</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2.238049</td>\n",
       "      <td>application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13556</th>\n",
       "      <td>2.224635</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7559</th>\n",
       "      <td>2.130467</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12272</th>\n",
       "      <td>2.110952</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14958</th>\n",
       "      <td>2.004516</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14813</th>\n",
       "      <td>1.991145</td>\n",
       "      <td>web</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>1.976309</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14259</th>\n",
       "      <td>1.951115</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>1.948272</td>\n",
       "      <td>build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14751</th>\n",
       "      <td>1.916680</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1.834936</td>\n",
       "      <td>api</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>1.826535</td>\n",
       "      <td>libraries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>1.757248</td>\n",
       "      <td>users</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1.746108</td>\n",
       "      <td>applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>1.740931</td>\n",
       "      <td>talk ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15058</th>\n",
       "      <td>1.668472</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>1.655269</td>\n",
       "      <td>library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>code backend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>backend services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>associate mod_wsgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>features mod_wsgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>consistency development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6946</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>job technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>installation hosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>hosting python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10964</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>real problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11799</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>secure low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>features help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>deployment performs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>considerable development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>current wsgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13559</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>time ancient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12176</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>sitting considerable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>best advantage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>containerised environments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>applications available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11260</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>request overloading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3016</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>current python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>containerised runtime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>created 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11575</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>runtime environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8253</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>measured</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8254</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>measured internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>learn mod_wsgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>considerable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12727</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>stream implementation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>0.033771</td>\n",
       "      <td>user mod_wsgi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       occurrences                       terms\n",
       "10529     8.321895                      python\n",
       "3077      4.995324                        data\n",
       "7698      4.851871                          ll\n",
       "13028     4.291750                        talk\n",
       "2108      4.186579                        code\n",
       "14177     3.030154                         use\n",
       "7266      2.635332                       learn\n",
       "8007      2.484063                        make\n",
       "14386     2.476606                       using\n",
       "13697     2.421009                       tools\n",
       "7337      2.347013                    learning\n",
       "13368     2.319585                     testing\n",
       "8899      2.273278                         new\n",
       "666       2.238049                 application\n",
       "13556     2.224635                        time\n",
       "7559      2.130467                        like\n",
       "12272     2.110952                    software\n",
       "14958     2.004516                        work\n",
       "14813     1.991145                         web\n",
       "8496      1.976309                       model\n",
       "14259     1.951115                        used\n",
       "1594      1.948272                       build\n",
       "14751     1.916680                         way\n",
       "600       1.834936                         api\n",
       "7456      1.826535                   libraries\n",
       "14338     1.757248                       users\n",
       "707       1.746108                applications\n",
       "13092     1.740931                     talk ll\n",
       "15058     1.668472                       world\n",
       "7493      1.655269                     library\n",
       "...            ...                         ...\n",
       "2118      0.033771                code backend\n",
       "1167      0.033771            backend services\n",
       "918       0.033771          associate mod_wsgi\n",
       "5019      0.033771           features mod_wsgi\n",
       "2666      0.033771     consistency development\n",
       "6946      0.033771            job technologies\n",
       "6626      0.033771        installation hosting\n",
       "6145      0.033771              hosting python\n",
       "10964     0.033771                real problem\n",
       "11799     0.033771                  secure low\n",
       "5011      0.033771               features help\n",
       "3457      0.033771         deployment performs\n",
       "2655      0.033771    considerable development\n",
       "3017      0.033771                current wsgi\n",
       "13559     0.033771                time ancient\n",
       "12176     0.033771        sitting considerable\n",
       "1370      0.033771              best advantage\n",
       "2696      0.033771  containerised environments\n",
       "709       0.033771      applications available\n",
       "11260     0.033771         request overloading\n",
       "3016      0.033771              current python\n",
       "2697      0.033771       containerised runtime\n",
       "2939      0.033771                created 2003\n",
       "11575     0.033771         runtime environment\n",
       "8253      0.033771                    measured\n",
       "8254      0.033771           measured internet\n",
       "7303      0.033771              learn mod_wsgi\n",
       "2654      0.033771                considerable\n",
       "12727     0.033771       stream implementation\n",
       "14331     0.033771               user mod_wsgi\n",
       "\n",
       "[15276 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrences = np.asarray(vectorized_text_labeled.sum(axis=0)).ravel()\n",
    "terms = (vectorizer.get_feature_names())\n",
    "counts_df = pd.DataFrame({'terms': terms, 'occurrences': occurrences}).sort_values('occurrences', ascending=False)\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3 Transform documents for prediction into document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data on which we will do our predictions, we will use the [transform](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.transform) method to get the document-term matrix.\n",
    "We will use this later, once we have our model ready. What should be the input to the `transform` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.54823703, 0.59136966, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.66890937, 0.        , 0.72153592, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.62016428, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.59136966,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.68715015]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text_predict = vectorizer.transform(terms)\n",
    "vectorized_text_predict.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Split into training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split our data into training set and testing set. This allows us to do cross validation and avoid overfitting. Use the `train_test_split` method from `sklearn.model_selection` to split the `vectorized_text_labeled` into training and testing set with the test size as one third of the size (0.3) of the labeled.\n",
    "\n",
    "[Here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) is the documentation for the function. The example usage should be helpful for understanding what `X_train, X_test, y_train, y_test` tuple represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-46cd959a5f2d>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-44-46cd959a5f2d>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    test_size=\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = df[df.year == 2017]['label']\n",
    "test_size= 100\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_text_labeled, labels, test_size=test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 Inspect the shape of each output of train_test_split\n",
    "For each of the output above, get the shape of the matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Train the model\n",
    "Finally we get to the stage for training the model. We are going to use a linear [support vector classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) and check its accuracy by using the `classification_report` function. Note that we have not done any parameter tuning done yet, so your model might not give you the best results. Like `TfIdfVectorizer` you can come back and tune these parameters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "classifier = LinearSVC(verbose=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model by using the the `classification_report` method from the [classification_report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html). What are the values of precision, recall and f1-scores? They are defined [here](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict( ... )\n",
    "report = sklearn.metrics.classification_report( ... , ... )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Make Predictions\n",
    "Use the model to predict which 2018 talks the user should go to. Plugin `vectorized_text_predict` from exercise 2.3 to get the `predicted_talks_vector` into the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_talks_vector = classifier.predict( ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `predicted_talk_indexes` get  the talk id, description, presenters, title and location and talk date.\n",
    "How many talks should the user go to according to your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df[df.year==2018]\n",
    "predicted_talk_indexes = predicted_talks_vector.nonzero()[0] + len(df[df.year==2017])\n",
    "\n",
    "df_2018_talks = df_2018.loc[predicted_talk_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "You might not be very happy with the results. You might want to reduce the manual steps for tuning the parameters. So where do you go from here?\n",
    "There are three specific next steps that can make this better.\n",
    "* [Spacy](https://spacy.io/) - This is an industrial strength natural language processeing libray that has a friendly api. This would be useful in your feature extraction steps.\n",
    "* Try using a different algorithm. [There is a lot](http://scikit-learn.org/stable/supervised_learning.html) to choose from.\n",
    "* [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) together make a great combination for automating the process of searching for the best models and parameters that accurately represent the patterns in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
